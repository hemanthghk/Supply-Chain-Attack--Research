# Supply-Chain-Attack--Research
ğŸ›¡ï¸ AI-Powered Traffic Monitoring for Supply Chain & MITM Attack Detection
ğŸ“ Presented as a research paper at Arizona State University â€“ IFT 525 (AI in Cybersecurity)

ğŸ“˜ About the Project
This project is a practical and research-driven attempt to solve a major cybersecurity challenge faced by enterprises todayâ€”supply chain attacks and Man-in-the-Middle (MITM) threats. With increasing reliance on third-party tools and services, traditional rule-based security systems are no longer enough. Many of these attacks go unnoticed, especially when they come from â€œtrustedâ€ vendors or are hidden inside encrypted traffic.

To address this, I developed an AI-based web traffic monitoring system that can detect suspicious behavior in real timeâ€”even when data is encrypted.

ğŸš€ What It Does
âœ… Monitors enterprise web and network traffic for anomalies

ğŸ§  Uses unsupervised machine learning (like Isolation Forest & DBSCAN) to detect unknown threats

ğŸ” Applies Explainable AI (XAI) tools like SHAP and LIME so analysts can understand why something was flagged

ğŸ”„ Incorporates Federated Learning to monitor third-party behavior without exposing sensitive data

ğŸ“Š Sends real-time alerts to a custom dashboard with clear, human-readable justifications

ğŸ§  Problem It Solves
Traditional security tools:

Are reactive and rule-based

Struggle with encrypted or obfuscated traffic

Canâ€™t explain their alerts (black-box problem)

Donâ€™t scale well with supply chain complexity

This system overcomes those gaps with AI-powered detection, privacy-preserving architecture, and transparency-focused design.

ğŸ§ª How It Works (Overview)
Data Ingestion: Network logs, app logs, threat intel feeds â†’ pulled in using Apache Kafka

Preprocessing: Feature extraction + anonymization (to protect sensitive info)

Anomaly Detection: Models like Isolation Forest and DBSCAN detect patterns that deviate from normal

Explainability Layer: SHAP and LIME explain the flagged anomalies in plain English

Federated Learning: Multiple nodes learn separately and update a global model without sharing raw data

Alert System: Analyst-friendly dashboard + API integration with Splunk and Elastic tools

ğŸ“Š Tech Stack
Python | Scikit-learn | TensorFlow | SHAP | LIME | Apache Kafka | AWS S3 | Wireshark | Splunk | Pandas

ğŸ” Key Features
Detects anomalous traffic even in encrypted communication

Preserves privacy with federated learning

Reduces false positives with intelligent clustering

Provides explainable alerts, so analysts know whatâ€™s going on

Built with a human-in-the-loop design for reliability

ğŸ“ˆ Validation & Testing
Used simulated enterprise network traffic + anonymized real logs

Measured accuracy, precision, recall, F1 score, and latency

Analysts rated alert clarity using XAI outputs

Tested using Scikit-learn, SHAP, LIME, and TensorFlow in a cloud-simulated enterprise setup

ğŸ§© What I Learned
How to design privacy-aware AI architectures for real-time security

The power of combining unsupervised ML + explainability

Working with Kafka pipelines, federated models, and adversarial testing

The importance of ethical AI: anonymization, fairness, transparency, and human oversight
